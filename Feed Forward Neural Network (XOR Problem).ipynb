{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ffnn model self.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keval47/Machine-Learning/blob/master/Delete%20Feed%20Forward%20Neural%20Network%20(XOR%20Problem).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFTtZ_Sg8T18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGlzoruW86XM",
        "colab_type": "code",
        "outputId": "d0b08b07-1cee-4bd4-fb1c-6ede9b3d2b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# prepare data XOR problem\n",
        "X_train = np.array([\n",
        "        [0,1],\n",
        "        [1,0],\n",
        "        [0,0],\n",
        "        [1,1]\n",
        "    ])\n",
        "y_train = np.array([[1,1,0,0]]).T\n",
        "print(y_train.shape)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nStkLOwg-wNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neuron:\n",
        "    def __init__(self,inputNeuron,hiddenNeuron,outputNeuron):\n",
        "        #here params 2,3,1 \n",
        "        #you can change accrding your data and hidden layer but output will be one because it required softmax activation\n",
        "        self.inputNeuron = inputNeuron\n",
        "        self.hiddenNeuron = hiddenNeuron\n",
        "        self.outputNeuron = outputNeuron\n",
        "\n",
        "        self.w_ih = np.random.random((inputNeuron,hiddenNeuron)) # (2x3) weights b/w input and hidden layer \n",
        "        self.w_ho = np.random.random((hiddenNeuron,outputNeuron)) # (3x1) weights b/w hidden and output layer\n",
        "        \n",
        "        self.b_ih = np.random.random((1,hiddenNeuron)) #(1x3) bias b/w input and hidden layer\n",
        "        self.b_ho = np.random.random((1,outputNeuron)) #(1x1) bias b/w  hidden and output layer\n",
        "\n",
        "        self.hiddenLayerOutput = np.array((hiddenNeuron,1)) # (3x1) just for store output generated by model\n",
        "        self.outputLayerOutput = np.array((outputNeuron,1)) # (1x1) just for store output generated by model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYhf5i7-8nru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ffnn:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def layers(self,inputNeuron,hiddenNeuron,outputNeuron):\n",
        "        self._neuron = Neuron(inputNeuron,hiddenNeuron,outputNeuron)# creating neurons\n",
        "\n",
        "    def hyper_params(self,lr=0.5,epochs=1000):\n",
        "        self._lr = lr # learning rate\n",
        "        self._epochs = epochs #iteration how many times data will be train\n",
        "\n",
        "    def fit(self,X,Y):\n",
        "        self._x = X\n",
        "        self._y = Y\n",
        "\n",
        "    # function for matrix multiplication you can also use np.dot\n",
        "    def _dot(self,a,b):\n",
        "        matmul = []\n",
        "        for val in a:\n",
        "            valSum = 0\n",
        "            for i in range(len(val)):\n",
        "                valSum += val[i] * b[i]\n",
        "            matmul.append(valSum)\n",
        "        return np.array(matmul)\n",
        "    \n",
        "    # squzze value in between 1/0. return probability\n",
        "    def _sigmoid(self,z,deriv=False):\n",
        "        if(deriv):\n",
        "            return z * (1-z)\n",
        "        return 1/(1+(np.exp(-z)))\n",
        "\n",
        "    # return weighted sum. return output based on weights\n",
        "    def _feedforward(self):\n",
        "        self._neuron.hiddenLayerOutput = self._sigmoid(self._dot(self._x,self._neuron.w_ih)+self._neuron.b_ih)\n",
        "        self._neuron.outputLayerOutput = self._sigmoid(self._dot(self._neuron.hiddenLayerOutput,self._neuron.w_ho)+self._neuron.b_ho)\n",
        "\n",
        "    # perform backpropagation. adjusts weights that let us close to accurate output \n",
        "    def _backProp(self):\n",
        "        err_ho = self._y - self._neuron.outputLayerOutput #calculate gradient of err. gradient=direction\n",
        "        slope_ho = self._sigmoid(self._neuron.outputLayerOutput,True) # calculate slope of output\n",
        "        delta_ho = err_ho * slope_ho #change in w_ho weights. define direction that make less error\n",
        "\n",
        "        err_ih = self._dot(delta_ho,self._neuron.w_ho.T)  # define gradient of err based on output layer error\n",
        "        slope_ih = self._sigmoid(self._neuron.hiddenLayerOutput,True) #calculate slope of hidden layer output\n",
        "        delta_ih = err_ih * slope_ih #change in i_ho weights. define direction that make less error\n",
        "        \n",
        "        # adjust weights to make less err\n",
        "        self._neuron.w_ih += self._dot(self._x.T,delta_ih) * self._lr #step further to defined direction by delta.step = learning rate\n",
        "        self._neuron.w_ho += self._dot(self._neuron.hiddenLayerOutput.T,delta_ho) * self._lr #step further to defined direction by delta. step = learning rate\n",
        "\n",
        "         # adjust bias to make less err\n",
        "        self._neuron.b_ih += np.sum(delta_ih,axis=0) * self._lr #step further to defined direction by delta. step = learning rate\n",
        "        self._neuron.b_ho += np.sum(delta_ho,axis=0) * self._lr #step further to defined direction by delta. step = learning rate\n",
        "\n",
        "    def _err(self):\n",
        "        # mean squared err\n",
        "        err = np.mean(np.square(self._y - self._neuron.outputLayerOutput))\n",
        "        return err\n",
        "\n",
        "    def predict(self,val):\n",
        "        # predict probability\n",
        "        # if you want to predict class then simply put threshold and filtered out class\n",
        "        return self._sigmoid(self._dot(val,self._neuron.w_ho)+self._neuron.b_ho)\n",
        "\n",
        "    def train(self,printErr=False):\n",
        "        # itrating over and over to make model train\n",
        "        for i in range(self._epochs):\n",
        "            self._feedforward()\n",
        "            self._backProp()\n",
        "            if(printErr):\n",
        "                # print err by every 100 iteration\n",
        "                if(i % 100 == 0):\n",
        "                    print(self._err())\n",
        "        return \"training finished\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGa14MxS8800",
        "colab_type": "code",
        "outputId": "8dc9644e-5237-4b27-c9e7-8eb25efb804a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# running model\n",
        "neuralnet = ffnn()\n",
        "neuralnet.hyper_params(lr=0.5,epochs=10000)\n",
        "neuralnet.layers(2,3,1)\n",
        "neuralnet.fit(X_train,y_train)\n",
        "neuralnet.train(printErr=False)\n",
        "neuralnet.predict(X_train)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99100364],\n",
              "       [0.01340017],\n",
              "       [0.0056239 ],\n",
              "       [0.99623408]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    }
  ]
}
